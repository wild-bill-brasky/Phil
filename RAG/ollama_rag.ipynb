{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0d60e71-b2fc-4a0b-b274-b7cb9ff452ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import utils as chromautils\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "#embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model_name = \"ibm-granite/granite-embedding-125m-english\"\n",
    "model = \"llama3.2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76b3b972-1cea-4b10-906f-e09214a187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_files_directory = \"/home/spinnaker/py_dev/wayback\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a620bdf-6b7a-485b-a3b9-cfae13c01567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_text_files(directory):\n",
    "    file_list = []\n",
    "    for (root, dirs, file) in os.walk(directory):\n",
    "        for f in file:\n",
    "            if '.txt' in f:\n",
    "                file_list.append(f'{root}/{f}')\n",
    "    return file_list\n",
    "\n",
    "# Specify the directory to search for PDF files\n",
    "txt_files = list_text_files(text_files_directory)\n",
    "num_files = len(txt_files)\n",
    "print(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b411b6d-624c-4f47-af1e-8cea04517459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and embed the content of the log files\n",
    "def load_and_embed_files(file_paths):\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        loader = UnstructuredLoader(file_path, mode=\"elements\")\n",
    "        documents.extend(loader.load_and_split())\n",
    "        documents = chromautils.filter_complex_metadata(documents)\n",
    "    return documents\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "documents = load_and_embed_files(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf077c85-eaf3-42fe-aa11-b762fbb9314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to store the Chroma vector store (in SQLite format)\n",
    "v_path_vector_store = '/home/spinnaker/py_dev/wayback/test4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028eb79-0b6d-48ea-b941-e885495b6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vector store from the documents / logs you provided\n",
    "vectorstore = Chroma.from_documents(documents=documents, embedding=embedding_model, persist_directory=v_path_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c6cc1-cc60-4ffc-b30c-6f4450f2db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vectorstore from disk\n",
    "chroma_db = Chroma(persist_directory=v_path_vector_store, embedding_function=embedding_model)\n",
    "type(chroma_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2053f1-ef5a-4f1c-bf7e-d1b22217cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = Ollama(model=model, verbose=False)  # Disable verbose for batch processing\n",
    "llm = ChatOllama(model=model, temperature=0.2, num_ctx=20000, verbose=False)\n",
    "print(f\"Loaded LLM model {llm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849df4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = chroma_db.as_retriever(search_kwargs={f\"k\": 5})  # Use the number of documents to retrieve\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=retriever,)\n",
    "\n",
    "# Use the 'invoke' method to handle the query\n",
    "result = qa_chain.invoke({\"query\": 'Review cyber attacks and malicious cyber activity that took place 2025 using the newly loaded context database. Use data from all sources at your disposal. After you have reviewed, write an intelligence report on the matter and provide specific dates if available. Provide specific analysis for any threat actors mentioned. Include a sources section at the end of the report.'})\n",
    "print(result.get('result'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-training",
   "language": "python",
   "name": "ai-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
